# Reading Assignment 1

[**Guidelines for Human-AI Interaction**](https://dl.acm.org/doi/10.1145/3290605.3300233)

0032763535 - Shuang Wu (wu1716)

## Summary

AI-infused systems get more popular nowadays, and AI has different traits from
traditional rule-based computer programs. For example, the AI behavior could be
uncertain and randomized to an extent, which requires us to have a more suitable
user interaction model for smoother UX. There are many suggestions about the UX
design for AI systems but they are often scattered around different sources in a
specific domain without systematic organization and experimental support. Thus,
the authors propose a set of design guidelines for human-AI interaction. These
general guidelines are based on several evaluations involving 49 participants
with 20 famous AI-infused applications. They should be general to apply to
different AI products in different domains.

The article describes the process of creating these design principles and the
reasons behind them in detail. 4 steps are involved in the process:

1. Consolidating guidelines from existing papers, public articles, and expert
   reviews.
2. Evaluating and removing the redundant or inapplicable rules from the
   collected guidelines
3. Conducting user study with 49 HCI practitioners
4. Iterating the guidelines based on the user study results and expert reviews

18 generally applicable design principles are proposed in the end. The authors
believe they can be a great help to design better, more human-centric AI-infused
applications.

## Insights

Good guidelines are the bedrock of design evaluation. It is helpful to have such
principles as the methodology to achieve our goal. The designers and engineers
can grasp the correct direction of UX improvement when evolving the products.

Though the guidelines are drawn for human-AI interaction, to me, nearly all the
guidelines are general enough to be applied to most the human-computer
interaction scenario. For example,

> G1: Make clear what the system can do.
>
> G2: Make clear how well the system can do what it can do.
>
> G11: Make clear why the system did what it did.
>
> G18: Notify users about changes.

Indeed, these guidelines are more important for the AI systems as they could be
more blurred to the users about the capability of the AI. However, they are also
an important rule when we design a traditional computer program. Giving the user
a clear and complete picture of features with solid scope and limitations is a
good practice to make the user feels the product is under control and
predictable. Just like the AI systems, rule-based computer applications will
also be likely to be changed or updated in future releases. In general UX
design, these guidelines are applicable to all kinds of software products.

Apart from that, some of the guidelines stress the importance of customization
and the ability to control. This includes:

> G12: Remember recent interactions.
>
> G15: Provide global controls.

From my experience, these guidelines need to be adjusted according to the target
user group. For instance, if the target users are common customers, most of the
time they will get overwhelmed by the high complexity of the product and
settings. In this case, cutting off the inessential customization options would
decrease the mental burden of the users, and thus improve the UX. On the other
hand, if the target audience is professionals, it is relatively possible that
they want to have more control over the system as they have a clearer
understanding of what they are trying to achieve with AI. As a result of that,
these guidelines are more suitable when we design AI-infused products for
professional users.

The process of distilling the design rules is generated by a small size of HCI
practitioners. Namely, there could be some biases in the result as they are not
the general public. There might be some details that are over-exaggerated or
underemphasized by the participants. Also, as the size of the case study is not
large enough, different opinions from different participants might be
conflicting with each other and thus be ignored in the final result. For
example, the paper shows that some participants think an AI system violates the
_G6: Mitigate social biases_ rule but another group of participants think it is
totally fine as they have a different definition of "biases" in their mind.

For the most part, the guidelines are well-organized and backed by a solid case
study and HCU exports. I believe they could be of great assistance to improve
the UX of systems in the AI era.
